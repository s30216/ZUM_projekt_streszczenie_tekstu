{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PCjke0vS7Nx"
   },
   "source": [
    "# Projekt ZUM - Streszczenie tekstu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WstÄ™pna analiza"
   ]
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZDp5cu7ZiZ2k",
    "outputId": "fe7acd8d-743d-4681-f399-0b008394ab29",
    "ExecuteTime": {
     "end_time": "2025-01-11T21:24:12.743909Z",
     "start_time": "2025-01-11T21:24:11.810415Z"
    }
   },
   "cell_type": "code",
   "source": "! pip install datasets transformers torch accelerate dash plotly jupyter-dash rouge-score",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (3.2.0)\r\n",
      "Requirement already satisfied: transformers in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (4.48.0)\r\n",
      "Requirement already satisfied: torch in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (2.5.1)\r\n",
      "Requirement already satisfied: accelerate in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (1.2.1)\r\n",
      "Requirement already satisfied: dash in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (2.18.2)\r\n",
      "Requirement already satisfied: plotly in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (5.24.1)\r\n",
      "Requirement already satisfied: jupyter-dash in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (0.4.2)\r\n",
      "Requirement already satisfied: rouge-score in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (0.1.2)\r\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from datasets) (3.16.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from datasets) (2.2.1)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from datasets) (18.1.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from datasets) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from datasets) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from datasets) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from datasets) (3.11.11)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from datasets) (0.27.1)\r\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from datasets) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from datasets) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from transformers) (0.21.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from transformers) (0.5.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from torch) (75.8.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: psutil in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from accelerate) (5.9.0)\r\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from dash) (3.0.3)\r\n",
      "Requirement already satisfied: Werkzeug<3.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from dash) (3.0.6)\r\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from dash) (2.0.0)\r\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from dash) (2.0.0)\r\n",
      "Requirement already satisfied: dash-table==5.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from dash) (5.0.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from dash) (8.5.0)\r\n",
      "Requirement already satisfied: retrying in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from dash) (1.3.4)\r\n",
      "Requirement already satisfied: nest-asyncio in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from dash) (1.6.0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from plotly) (9.0.0)\r\n",
      "Requirement already satisfied: ipython in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from jupyter-dash) (8.30.0)\r\n",
      "Requirement already satisfied: ipykernel in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from jupyter-dash) (6.29.5)\r\n",
      "Requirement already satisfied: ansi2html in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from jupyter-dash) (1.9.2)\r\n",
      "Requirement already satisfied: absl-py in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from rouge-score) (2.1.0)\r\n",
      "Requirement already satisfied: nltk in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from rouge-score) (3.9.1)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from rouge-score) (1.16.0)\r\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\r\n",
      "Requirement already satisfied: click>=8.1.3 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from Flask<3.1,>=1.0.4->dash) (8.1.8)\r\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from Flask<3.1,>=1.0.4->dash) (1.9.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from aiohttp->datasets) (24.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.12.14)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from importlib-metadata->dash) (3.21.0)\r\n",
      "Requirement already satisfied: appnope in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from ipykernel->jupyter-dash) (0.1.3)\r\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from ipykernel->jupyter-dash) (0.2.1)\r\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from ipykernel->jupyter-dash) (1.6.7)\r\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from ipykernel->jupyter-dash) (8.6.0)\r\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from ipykernel->jupyter-dash) (5.7.2)\r\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from ipykernel->jupyter-dash) (0.1.6)\r\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from ipykernel->jupyter-dash) (26.2.0)\r\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from ipykernel->jupyter-dash) (6.4.2)\r\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from ipykernel->jupyter-dash) (5.14.3)\r\n",
      "Requirement already satisfied: decorator in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from ipython->jupyter-dash) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from ipython->jupyter-dash) (0.19.2)\r\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from ipython->jupyter-dash) (3.0.43)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from ipython->jupyter-dash) (2.15.1)\r\n",
      "Requirement already satisfied: stack-data in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from ipython->jupyter-dash) (0.2.0)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from ipython->jupyter-dash) (4.8.0)\r\n",
      "Requirement already satisfied: joblib in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from nltk->rouge-score) (1.4.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from jedi>=0.16->ipython->jupyter-dash) (0.8.4)\r\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter-dash) (3.10.0)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from pexpect>4.3->ipython->jupyter-dash) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->jupyter-dash) (0.2.5)\r\n",
      "Requirement already satisfied: executing in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from stack-data->ipython->jupyter-dash) (0.8.3)\r\n",
      "Requirement already satisfied: asttokens in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from stack-data->ipython->jupyter-dash) (2.0.5)\r\n",
      "Requirement already satisfied: pure-eval in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages (from stack-data->ipython->jupyter-dash) (0.2.2)\r\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIUh2ND8iocS",
    "outputId": "70848d85-24d8-40dd-a639-7b21f9a9245a",
    "ExecuteTime": {
     "end_time": "2025-01-11T21:24:19.335479Z",
     "start_time": "2025-01-11T21:24:12.751469Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\")\n",
    "df_train = ds['train'].to_pandas().loc[:100]\n",
    "df_val = ds['validation'].to_pandas()\n",
    "df_test = ds['test'].to_pandas()"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T21:24:19.358019Z",
     "start_time": "2025-01-11T21:24:19.355192Z"
    }
   },
   "source": [
    "ds"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T21:24:19.394557Z",
     "start_time": "2025-01-11T21:24:19.382427Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "df_train"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 article  \\\n",
       "0    LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported Â£20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, ...   \n",
       "1    Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the mo...   \n",
       "2    MINNEAPOLIS, Minnesota (CNN) -- Drivers who were on the Minneapolis bridge when it collapsed told harrowing tales of survival. \"The whole bridge from one side of the Mississippi to the other just completely gave way, fell all the way down,\" survivor Gary Babineau told CNN. \"I probably had a 30-, 35-foot free fall. And there's cars in the water, there's cars on fire. The whole bridge is down.\" He said his back was injured but he determined he could move around. \"I realized there was a school ...   \n",
       "3    WASHINGTON (CNN) -- Doctors removed five small polyps from President Bush's colon on Saturday, and \"none appeared worrisome,\" a White House spokesman said. The polyps were removed and sent to the National Naval Medical Center in Bethesda, Maryland, for routine microscopic examination, spokesman Scott Stanzel said. Results are expected in two to three days. All were small, less than a centimeter [half an inch] in diameter, he said. Bush is in good humor, Stanzel said, and will resume his acti...   \n",
       "4    (CNN)  -- The National Football League has indefinitely suspended Atlanta Falcons quarterback Michael Vick without pay, officials with the league said Friday. NFL star Michael Vick is set to appear in court Monday. A judge will have the final say on a plea deal. Earlier, Vick admitted to participating in a dogfighting ring as part of a plea agreement with federal prosecutors in Virginia. \"Your admitted conduct was not only illegal, but also cruel and reprehensible. Your team, the NFL, and NF...   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "96   LONDON, England (CNN) -- Previously unseen footage of Diana, Princess of Wales, taken just hours before she was killed in a car crash, has been shown to the jury at the inquest into her death. The footage showed Diana and Dodi step into an elevator at the Ritz Hotel. Images taken from a security camera at the Ritz Hotel in Paris show the 36-year-old smiling as she and her lover Dodi Fayed step into an elevator and later walk out of the hotel. Further footage shows Fayed visiting a jeweler's ...   \n",
       "97   WASHINGTON (CNN) -- Republicans reacted with surprise and recrimination Sunday to blistering criticism of the Iraq war from former coalition commander retired Lt. Gen. Ricardo Sanchez. Lawmakers lashed back at retired Gen. Ricardo Sanchez on Sunday after he criticized the war effort. On Friday, Sanchez, who was coalition commander in 2003 and 2004, called the Iraq war \"a nightmare with no end in sight.\" He said the Bush administration, the State Department and Congress all share blame. Speak...   \n",
       "98   ST. PETERSBURG, Florida (CNN) -- The acrimony from the Republican campaign trail carried over quickly into the CNN/YouTube GOP presidential debate Wednesday. The debate marked the first time the candidates had faced off on the same stage in over a month. With five weeks to go until the first contest of the 2008 nominating season, the Republican candidates engaged in a free-for-all, trying to differentiate their views on immigration, the Iraq war, abortion, gun control and even whether they b...   \n",
       "99   BAGHDAD, Iraq (CNN) -- None of the 1,000-plus Iraqi detainees freed in recent weeks have broken a pledge not to return to the insurgency, according to the Marine general who oversees the U.S. detention centers in Iraq. A U.S. military panel reviews a detainee's case at Camp Cropper near Baghdad. Speaking in Arabic, Maj. Gen. Doug Stone on Wednesday reassured Iraqis about how the 25,000 detainees -- mostly Sunnis -- are treated after being taken into custody on suspicion of involvement in the...   \n",
       "100  (CNN) -- The Tennessee Supreme Court on Wednesday refused to modify or overturn a lower court's ruling allowing Mary Winkler, convicted of killing her minister husband, visitation rights with the couple's three daughters. Holding baby Brianna, Mary Winkler stands next to Matthew. In the foreground are Mary Alice and Patricia. Charles and Diane Winkler, parents of slain minister Matthew Winkler, had asked the court to intervene and either revoke Mary Winkler's visitation rights or allow them ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                           highlights  \\\n",
       "0                                                                         Harry Potter star Daniel Radcliffe gets Â£20M fortune as he turns 18 Monday .\\nYoung actor says he has no plans to fritter his cash away .\\nRadcliffe's earnings from first five Potter films have been held in trust fund .   \n",
       "1        Mentally ill inmates in Miami are housed on the \"forgotten floor\"\\nJudge Steven Leifman says most are there as a result of \"avoidable felonies\"\\nWhile CNN tours facility, patient shouts: \"I am the son of the president\"\\nLeifman says the system is unjust and he's fighting for change .   \n",
       "2                                                                 NEW: \"I thought I was going to die,\" driver says .\\nMan says pickup truck was folded in half; he just has cut on face .\\nDriver: \"I probably had a 30-, 35-foot free fall\"\\nMinnesota bridge collapsed during rush hour Wednesday .   \n",
       "3                                                                                                         Five small polyps found during procedure; \"none worrisome,\" spokesman says .\\nPresident reclaims powers transferred to vice president .\\nBush undergoes routine colonoscopy at Camp David .   \n",
       "4                NEW: NFL chief, Atlanta Falcons owner critical of Michael Vick's conduct .\\nNFL suspends Falcons quarterback indefinitely without pay .\\nVick admits funding dogfighting operation but says he did not gamble .\\nVick due in federal court Monday; future in NFL remains uncertain .   \n",
       "..                                                                                                                                                                                                                                                                                                ...   \n",
       "96   NEW: Jury shown new footage of Diana taken hours before her death .\\nDiana and Dodi Fayed inquest jury to hear \"scene setting\" evidence .\\nOn Tuesday coroner outlined controversial claims, published new images .\\nCourt will make final decision on what happened in car crash 10 years ago .   \n",
       "97           Republican Sen. Lindsey Graham: \"I am astounded\" by comments .\\nSanchez, a retired former coalition commander in Iraq, called war \"nightmare\"\\nRepublican Sen. John McCain wishes Sanchez would have spoken up earlier .\\nRepublican Sen. Mitch McConnell said Sanchez is simply wrong .   \n",
       "98                      YouTube questions address taxes, the Bible, abortion, gun control .\\nGiuliani, Romney, Huckabee spar over immigration .\\nMcCain challenges Paul over suggestion to bring troops home from Iraq .\\nNearly 5,000 videos for the GOP debate; 2,000 more than Democratic debate .   \n",
       "99                            More than 1,000 freed detainees reportedly keep pledge not to rejoin insurgency .\\nU.S. general tries to reassure Sunnis that detainees face no abuse .\\nMore than 80 percent of detainees are Sunnis .\\nU.S. airstrike kills 13 suspected terrorists west of Baghdad .   \n",
       "100                          Mary Winkler convicted earlier this year of shooting her husband to death .\\nWinkler served time and was released; the couple had three children .\\nThe children live with their grandparents, who oppose visitation .\\nWinkler has not seen her children in 15 months .   \n",
       "\n",
       "                                           id  \n",
       "0    42c027e4ff9730fbb3de84c1af0d2c506e41c3e4  \n",
       "1    ee8871b15c50d0db17b0179a6d2beab35065f1e9  \n",
       "2    06352019a19ae31e527f37f7571c6dd7f0c5da37  \n",
       "3    24521a2abb2e1f5e34e6824e0f9e56904a2b0e88  \n",
       "4    7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a  \n",
       "..                                        ...  \n",
       "96   a3dd38ec7bc9d7e8423b96d8fd0641a2a5d5c984  \n",
       "97   654c6b29b96d2a5a818d91400c20f838b0e8b6df  \n",
       "98   764d9ce99a1e3f79d95fbc4b68adbce14e7f8bcd  \n",
       "99   f16446db34e2861f0450dfa34d8cdda541ab7b19  \n",
       "100  3e910c5b8425cd7c871a402a32ca44680b53ce5e  \n",
       "\n",
       "[101 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported Â£20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, ...</td>\n",
       "      <td>Harry Potter star Daniel Radcliffe gets Â£20M fortune as he turns 18 Monday .\\nYoung actor says he has no plans to fritter his cash away .\\nRadcliffe's earnings from first five Potter films have been held in trust fund .</td>\n",
       "      <td>42c027e4ff9730fbb3de84c1af0d2c506e41c3e4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the mo...</td>\n",
       "      <td>Mentally ill inmates in Miami are housed on the \"forgotten floor\"\\nJudge Steven Leifman says most are there as a result of \"avoidable felonies\"\\nWhile CNN tours facility, patient shouts: \"I am the son of the president\"\\nLeifman says the system is unjust and he's fighting for change .</td>\n",
       "      <td>ee8871b15c50d0db17b0179a6d2beab35065f1e9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MINNEAPOLIS, Minnesota (CNN) -- Drivers who were on the Minneapolis bridge when it collapsed told harrowing tales of survival. \"The whole bridge from one side of the Mississippi to the other just completely gave way, fell all the way down,\" survivor Gary Babineau told CNN. \"I probably had a 30-, 35-foot free fall. And there's cars in the water, there's cars on fire. The whole bridge is down.\" He said his back was injured but he determined he could move around. \"I realized there was a school ...</td>\n",
       "      <td>NEW: \"I thought I was going to die,\" driver says .\\nMan says pickup truck was folded in half; he just has cut on face .\\nDriver: \"I probably had a 30-, 35-foot free fall\"\\nMinnesota bridge collapsed during rush hour Wednesday .</td>\n",
       "      <td>06352019a19ae31e527f37f7571c6dd7f0c5da37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON (CNN) -- Doctors removed five small polyps from President Bush's colon on Saturday, and \"none appeared worrisome,\" a White House spokesman said. The polyps were removed and sent to the National Naval Medical Center in Bethesda, Maryland, for routine microscopic examination, spokesman Scott Stanzel said. Results are expected in two to three days. All were small, less than a centimeter [half an inch] in diameter, he said. Bush is in good humor, Stanzel said, and will resume his acti...</td>\n",
       "      <td>Five small polyps found during procedure; \"none worrisome,\" spokesman says .\\nPresident reclaims powers transferred to vice president .\\nBush undergoes routine colonoscopy at Camp David .</td>\n",
       "      <td>24521a2abb2e1f5e34e6824e0f9e56904a2b0e88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN)  -- The National Football League has indefinitely suspended Atlanta Falcons quarterback Michael Vick without pay, officials with the league said Friday. NFL star Michael Vick is set to appear in court Monday. A judge will have the final say on a plea deal. Earlier, Vick admitted to participating in a dogfighting ring as part of a plea agreement with federal prosecutors in Virginia. \"Your admitted conduct was not only illegal, but also cruel and reprehensible. Your team, the NFL, and NF...</td>\n",
       "      <td>NEW: NFL chief, Atlanta Falcons owner critical of Michael Vick's conduct .\\nNFL suspends Falcons quarterback indefinitely without pay .\\nVick admits funding dogfighting operation but says he did not gamble .\\nVick due in federal court Monday; future in NFL remains uncertain .</td>\n",
       "      <td>7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>LONDON, England (CNN) -- Previously unseen footage of Diana, Princess of Wales, taken just hours before she was killed in a car crash, has been shown to the jury at the inquest into her death. The footage showed Diana and Dodi step into an elevator at the Ritz Hotel. Images taken from a security camera at the Ritz Hotel in Paris show the 36-year-old smiling as she and her lover Dodi Fayed step into an elevator and later walk out of the hotel. Further footage shows Fayed visiting a jeweler's ...</td>\n",
       "      <td>NEW: Jury shown new footage of Diana taken hours before her death .\\nDiana and Dodi Fayed inquest jury to hear \"scene setting\" evidence .\\nOn Tuesday coroner outlined controversial claims, published new images .\\nCourt will make final decision on what happened in car crash 10 years ago .</td>\n",
       "      <td>a3dd38ec7bc9d7e8423b96d8fd0641a2a5d5c984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>WASHINGTON (CNN) -- Republicans reacted with surprise and recrimination Sunday to blistering criticism of the Iraq war from former coalition commander retired Lt. Gen. Ricardo Sanchez. Lawmakers lashed back at retired Gen. Ricardo Sanchez on Sunday after he criticized the war effort. On Friday, Sanchez, who was coalition commander in 2003 and 2004, called the Iraq war \"a nightmare with no end in sight.\" He said the Bush administration, the State Department and Congress all share blame. Speak...</td>\n",
       "      <td>Republican Sen. Lindsey Graham: \"I am astounded\" by comments .\\nSanchez, a retired former coalition commander in Iraq, called war \"nightmare\"\\nRepublican Sen. John McCain wishes Sanchez would have spoken up earlier .\\nRepublican Sen. Mitch McConnell said Sanchez is simply wrong .</td>\n",
       "      <td>654c6b29b96d2a5a818d91400c20f838b0e8b6df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ST. PETERSBURG, Florida (CNN) -- The acrimony from the Republican campaign trail carried over quickly into the CNN/YouTube GOP presidential debate Wednesday. The debate marked the first time the candidates had faced off on the same stage in over a month. With five weeks to go until the first contest of the 2008 nominating season, the Republican candidates engaged in a free-for-all, trying to differentiate their views on immigration, the Iraq war, abortion, gun control and even whether they b...</td>\n",
       "      <td>YouTube questions address taxes, the Bible, abortion, gun control .\\nGiuliani, Romney, Huckabee spar over immigration .\\nMcCain challenges Paul over suggestion to bring troops home from Iraq .\\nNearly 5,000 videos for the GOP debate; 2,000 more than Democratic debate .</td>\n",
       "      <td>764d9ce99a1e3f79d95fbc4b68adbce14e7f8bcd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BAGHDAD, Iraq (CNN) -- None of the 1,000-plus Iraqi detainees freed in recent weeks have broken a pledge not to return to the insurgency, according to the Marine general who oversees the U.S. detention centers in Iraq. A U.S. military panel reviews a detainee's case at Camp Cropper near Baghdad. Speaking in Arabic, Maj. Gen. Doug Stone on Wednesday reassured Iraqis about how the 25,000 detainees -- mostly Sunnis -- are treated after being taken into custody on suspicion of involvement in the...</td>\n",
       "      <td>More than 1,000 freed detainees reportedly keep pledge not to rejoin insurgency .\\nU.S. general tries to reassure Sunnis that detainees face no abuse .\\nMore than 80 percent of detainees are Sunnis .\\nU.S. airstrike kills 13 suspected terrorists west of Baghdad .</td>\n",
       "      <td>f16446db34e2861f0450dfa34d8cdda541ab7b19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>(CNN) -- The Tennessee Supreme Court on Wednesday refused to modify or overturn a lower court's ruling allowing Mary Winkler, convicted of killing her minister husband, visitation rights with the couple's three daughters. Holding baby Brianna, Mary Winkler stands next to Matthew. In the foreground are Mary Alice and Patricia. Charles and Diane Winkler, parents of slain minister Matthew Winkler, had asked the court to intervene and either revoke Mary Winkler's visitation rights or allow them ...</td>\n",
       "      <td>Mary Winkler convicted earlier this year of shooting her husband to death .\\nWinkler served time and was released; the couple had three children .\\nThe children live with their grandparents, who oppose visitation .\\nWinkler has not seen her children in 15 months .</td>\n",
       "      <td>3e910c5b8425cd7c871a402a32ca44680b53ce5e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBeU4bnjiezq",
    "outputId": "a3a122bf-53e3-407a-b51c-769456530bde",
    "ExecuteTime": {
     "end_time": "2025-01-11T21:24:19.429818Z",
     "start_time": "2025-01-11T21:24:19.424928Z"
    }
   },
   "source": [
    "# wyÅ›wietlanie przykÅ‚adowej pary tekst - streszczenie\n",
    "df_train.head(1)[[\"article\", \"highlights\"]]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               article  \\\n",
       "0  LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported Â£20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, ...   \n",
       "\n",
       "                                                                                                                                                                                                                    highlights  \n",
       "0  Harry Potter star Daniel Radcliffe gets Â£20M fortune as he turns 18 Monday .\\nYoung actor says he has no plans to fritter his cash away .\\nRadcliffe's earnings from first five Potter films have been held in trust fund .  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported Â£20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, ...</td>\n",
       "      <td>Harry Potter star Daniel Radcliffe gets Â£20M fortune as he turns 18 Monday .\\nYoung actor says he has no plans to fritter his cash away .\\nRadcliffe's earnings from first five Potter films have been held in trust fund .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8METFZfyjAfa",
    "outputId": "43c12da3-334a-4bb1-a7f0-f70346996ba9",
    "ExecuteTime": {
     "end_time": "2025-01-11T21:24:19.484246Z",
     "start_time": "2025-01-11T21:24:19.477450Z"
    }
   },
   "source": [
    "# Å›rednia dÅ‚ugoÅ›Ä‡ tekstu i Å›rednia dÅ‚ugoÅ›Ä‡ streszczeÅ„\n",
    "import numpy as np\n",
    "\n",
    "def words_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "text_len = [words_count(x) for x in df_train[\"article\"]]\n",
    "summary_len = [words_count(x) for x in df_train[\"highlights\"]]\n",
    "\n",
    "print(f\"Å›rednia dÅ‚ugoÅ›Ä‡ tekstu (wyrazy): {np.mean(text_len)}\")\n",
    "print(f\"Å›rednia dÅ‚ugoÅ›Ä‡ streszczeÅ„ (wyrazy): {np.mean(summary_len)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Å›rednia dÅ‚ugoÅ›Ä‡ tekstu (wyrazy): 605.4356435643564\n",
      "Å›rednia dÅ‚ugoÅ›Ä‡ streszczeÅ„ (wyrazy): 41.524752475247524\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8d62PIrV_4r",
    "outputId": "852c4579-3e0f-4ab5-9e74-c9dfad6565d0",
    "ExecuteTime": {
     "end_time": "2025-01-11T21:24:19.558817Z",
     "start_time": "2025-01-11T21:24:19.556555Z"
    }
   },
   "source": [
    "ratios = [s_len / t_len for s_len, t_len in zip(summary_len, text_len)]\n",
    "print(f\"Åšrednia proporcja dÅ‚ugoÅ›ci streszczeÅ„ do tekstÃ³w: {np.mean(ratios):.2f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Åšrednia proporcja dÅ‚ugoÅ›ci streszczeÅ„ do tekstÃ³w: 0.09\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "1oUj3H26UvJ5",
    "outputId": "364e8669-c457-4375-aadf-ec10d6de6459",
    "ExecuteTime": {
     "end_time": "2025-01-11T21:24:19.803824Z",
     "start_time": "2025-01-11T21:24:19.599887Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histogramy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(text_len, bins=50, alpha=0.7, label=\"DÅ‚ugoÅ›ci tekstÃ³w\")\n",
    "plt.hist(summary_len, bins=50, alpha=0.7, label=\"DÅ‚ugoÅ›ci streszczeÅ„\")\n",
    "plt.legend()\n",
    "plt.title(\"Histogram dÅ‚ugoÅ›ci tekstÃ³w i streszczeÅ„\")\n",
    "plt.xlabel(\"DÅ‚ugoÅ›Ä‡\")\n",
    "plt.ylabel(\"Liczba przykÅ‚adÃ³w\")\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3u-q7GXVklR",
    "outputId": "4658c254-7b02-4851-ce00-8954f6199eee",
    "ExecuteTime": {
     "end_time": "2025-01-11T21:24:19.889018Z",
     "start_time": "2025-01-11T21:24:19.873696Z"
    }
   },
   "source": [
    "# NajdÅ‚uÅ¼szy i najkrÃ³tszy artykuÅ‚\n",
    "longest_article = max(df_train[\"article\"], key=lambda x: words_count(x))\n",
    "shortest_article = min(df_train[\"article\"], key=lambda x: words_count(x))\n",
    "\n",
    "print(f\"NajdÅ‚uÅ¼szy artykuÅ‚ (liczba sÅ‚Ã³w: {words_count(longest_article)}):\\n{longest_article[:500]}...\\n\")\n",
    "print(f\"NajkrÃ³tszy artykuÅ‚ (liczba sÅ‚Ã³w: {words_count(shortest_article)}):\\n{shortest_article[:500]}\\n\")\n",
    "\n",
    "# NajdÅ‚uÅ¼sze i najkrÃ³tsze streszczenie\n",
    "longest_summary = max(df_train[\"highlights\"], key=lambda x: words_count(x))\n",
    "shortest_summary = min(df_train[\"highlights\"], key=lambda x: words_count(x))\n",
    "\n",
    "print(f\"NajdÅ‚uÅ¼sze streszczenie (liczba sÅ‚Ã³w: {words_count(longest_summary)}):\\n{longest_summary[:500]}...\\n\")\n",
    "print(f\"NajkrÃ³tsze streszczenie (liczba sÅ‚Ã³w: {words_count(shortest_summary)}):\\n{shortest_summary[:500]}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NajdÅ‚uÅ¼szy artykuÅ‚ (liczba sÅ‚Ã³w: 1665):\n",
      "LONDON, England (CNN) -- Prince Harry led tributes to Diana, Princess of Wales on the 10th anniversary of her death, describing her as \"the best mother in the world\" in a speech at a memorial service. Here is his speech in full: . William and I can separate life into two parts. There were those years when we were blessed with the physical presence beside us of both our mother and father. Princes Harry and William greet guests at a thanksgiving service in memory of their mother. And then there ar...\n",
      "\n",
      "NajkrÃ³tszy artykuÅ‚ (liczba sÅ‚Ã³w: 158):\n",
      "(CNN) -- The company was founded in 1985 by seven communications industry veterans -- Franklin Antonio, Adelia Coffman, Andrew Cohen, Klein Gilhousen, Irwin Jacobs, Andrew Viterbi and Harvey White. One of Qualcomm's first products was OmniTRACS, introduced in 1988, which is currently the largest satellite-based commercial mobile system for the transportation industry. Today, Qualcomm's patent portfolio includes approximately 6,100 United States patents and patent applications for CDMA and relate\n",
      "\n",
      "NajdÅ‚uÅ¼sze streszczenie (liczba sÅ‚Ã³w: 56):\n",
      "Organ shortage in rich states has created a trade from poorer countries .\n",
      "\"Transplant tourists\" travel to poor countries to buy organs from the desperate .\n",
      "Pakistan, where trade in human organs is legal, is turning into a \"kidney bazaar\"\n",
      "Patients pay $8,500 for a new kidney, while donors are paid just $300 to $1,000 ....\n",
      "\n",
      "NajkrÃ³tsze streszczenie (liczba sÅ‚Ã³w: 26):\n",
      "John Lewis Partnership began as a shop on London's Oxford street in 1864 .\n",
      "All 67,100 employees are partners in the organization and own shares .\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T21:24:19.912568Z",
     "start_time": "2025-01-11T21:24:19.903330Z"
    }
   },
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Tokenizacja i liczenie sÅ‚Ã³w\n",
    "df_train['article_word_count'] = df_train['article'].apply(lambda x: words_count(x))\n",
    "df_train['summary_word_count'] = df_train['highlights'].apply(lambda x: words_count(x))\n",
    "\n",
    "# NajczÄ™Å›ciej wystÄ™pujÄ…ce sÅ‚owa w streszczeniach\n",
    "all_summaries = \" \".join(df_train['highlights'])\n",
    "word_counts = Counter(all_summaries.split())\n",
    "print(word_counts.most_common(10))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 318), ('to', 107), ('in', 102), ('of', 92), ('the', 90), ('a', 58), ('for', 45), ('says', 40), ('and', 39), ('is', 38)]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InÅ¼ynieria cech"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T21:24:20.021906Z",
     "start_time": "2025-01-11T21:24:19.939872Z"
    }
   },
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "  text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "  text = text.strip().replace('\\n', ' ').replace('\\r', ' ')\n",
    "  text = re.sub(r'\\s+', ' ', text)\n",
    "  return text\n",
    "\n",
    "train_data = ds['train']\n",
    "train_data = train_data_map = train_data.map(lambda x: {'article': clean_text(x['article']), 'highlights': clean_text(x['highlights'])})\n",
    "val_data = ds['validation'].map(lambda x: {'article': clean_text(x['article']), 'highlights': clean_text(x['highlights'])})\n",
    "test_data = ds['test'].map(lambda x: {'article': clean_text(x['article']), 'highlights': clean_text(x['highlights'])})\n",
    "\n",
    "train_data[:2], val_data[:2], test_data[:2]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'article': ['LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported Â£20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films. Watch I-Reporter give her review of Potter\\'s latest Â» . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.',\n",
       "   'Editor\\'s note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O\\'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most severe mental illnesses are incarcerated until they\\'re ready to appear in court. Most often, they face drug charges or charges of assaulting an officer --charges that Judge Steven Leifman says are usually \"avoidable felonies.\" He says the arrests often result from confrontations with police. Mentally ill people often won\\'t do what they\\'re told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid, delusional, and less likely to follow directions, according to Leifman. So, they end up on the ninth floor severely mentally disturbed, but not getting any real help because they\\'re in jail. We toured the jail with Leifman. He is well known in Miami as an advocate for justice and the mentally ill. Even though we were not exactly welcomed with open arms by the guards, we were given permission to shoot videotape and tour the floor. Go inside the \\'forgotten floor\\' Â» . At first, it\\'s hard to determine where the people are. The prisoners are wearing sleeveless robes. Imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that\\'s kind of what they look like. They\\'re designed to keep the mentally ill patients from injuring themselves. That\\'s also why they have no shoes, laces or mattresses. Leifman says about one-third of all people in Miami-Dade county jails are mentally ill. So, he says, the sheer volume is overwhelming the system, and the result is what we see on the ninth floor. Of course, it is a jail, so it\\'s not supposed to be warm and comforting, but the lights glare, the cells are tiny and it\\'s loud. We see two, sometimes three men -- sometimes in the robes, sometimes naked, lying or sitting in their cells. \"I am the son of the president. You need to get me out of here!\" one man shouts at me. He is absolutely serious, convinced that help is on the way -- if only he could reach the White House. Leifman tells me that these prisoner-patients will often circulate through the system, occasionally stabilizing in a mental hospital, only to return to jail to face their charges. It\\'s brutally unjust, in his mind, and he has become a strong advocate for changing things in Miami. Over a meal later, we talk about how things got this way for mental patients. Leifman says 200 years ago people were considered \"lunatics\" and they were locked up in jails even if they had no charges against them. They were just considered unfit to be in society. Over the years, he says, there was some public outcry, and the mentally ill were moved out of jails and into hospitals. But Leifman says many of these mental hospitals were so horrible they were shut down. Where did the patients go? Nowhere. The streets. They became, in many cases, the homeless, he says. They never got treatment. Leifman says in 1955 there were more than half a million people in state mental hospitals, and today that number has been reduced 90 percent, and 40,000 to 50,000 people are in mental hospitals. The judge says he\\'s working to change this. Starting in 2008, many inmates who would otherwise have been brought to the \"forgotten floor\" will instead be sent to a new mental health facility -- the first step on a journey toward long-term treatment, not just punishment. Leifman says it\\'s not the complete answer, but it\\'s a start. Leifman says the best part is that it\\'s a win-win solution. The patients win, the families are relieved, and the state saves money by simply not cycling these prisoners through again and again. And, for Leifman, justice is served. E-mail to a friend .'],\n",
       "  'highlights': [\"Harry Potter star Daniel Radcliffe gets Â£20M fortune as he turns 18 Monday . Young actor says he has no plans to fritter his cash away . Radcliffe's earnings from first five Potter films have been held in trust fund .\",\n",
       "   'Mentally ill inmates in Miami are housed on the \"forgotten floor\" Judge Steven Leifman says most are there as a result of \"avoidable felonies\" While CNN tours facility, patient shouts: \"I am the son of the president\" Leifman says the system is unjust and he\\'s fighting for change .'],\n",
       "  'id': ['42c027e4ff9730fbb3de84c1af0d2c506e41c3e4',\n",
       "   'ee8871b15c50d0db17b0179a6d2beab35065f1e9']},\n",
       " {'article': ['(CNN)Share, and your gift will be multiplied. That may sound like an esoteric adage, but when Zully Broussard selflessly decided to give one of her kidneys to a stranger, her generosity paired up with big data. It resulted in six patients receiving transplants. That surprised and wowed her. \"I thought I was going to help this one person who I don\\'t know, but the fact that so many people can have a life extension, that\\'s pretty big,\" Broussard told CNN affiliate KGO. She may feel guided in her generosity by a higher power. \"Thanks for all the support and prayers,\" a comment on a Facebook page in her name read. \"I know this entire journey is much bigger than all of us. I also know I\\'m just the messenger.\" CNN cannot verify the authenticity of the page. But the power that multiplied Broussard\\'s gift was data processing of genetic profiles from donor-recipient pairs. It works on a simple swapping principle but takes it to a much higher level, according to California Pacific Medical Center in San Francisco. So high, that it is taking five surgeons, a covey of physician assistants, nurses and anesthesiologists, and more than 40 support staff to perform surgeries on 12 people. They are extracting six kidneys from donors and implanting them into six recipients. \"The ages of the donors and recipients range from 26 to 70 and include three parent and child pairs, one sibling pair and one brother and sister-in-law pair,\" the medical center said in a statement. The chain of surgeries is to be wrapped up Friday. In late March, the medical center is planning to hold a reception for all 12 patients. Here\\'s how the super swap works, according to California Pacific Medical Center. Say, your brother needs a kidney to save his life, or at least get off of dialysis, and you\\'re willing to give him one of yours. But then it turns out that your kidney is not a match for him, and it\\'s certain his body would reject it. Your brother can then get on a years-long waiting list for a kidney coming from an organ donor who died. Maybe that will work out -- or not, and time could run out for him. Alternatively, you and your brother could look for another recipient-living donor couple like yourselves -- say, two more siblings, where the donor\\'s kidney isn\\'t suited for his sister, the recipient. But maybe your kidney is a match for his sister, and his kidney is a match for your brother. So, you\\'d do a swap. That\\'s called a paired donation. It\\'s a bit of a surgical square dance, where four people cross over partners temporarily and everybody goes home smiling. But instead of a square dance, Broussard\\'s generous move set off a chain reaction, like dominoes falling. Her kidney, which was removed Thursday, went to a recipient, who was paired with a donor. That donor\\'s kidney went to the next recipient, who was also paired with a donor, and so on. On Friday, the last donor will give a kidney to someone who has been biding time on one of those deceased donor lists to complete the chain. Such long-chain transplanting is rare. It\\'s been done before, California Pacific Medical Center said in a statement, but matching up the people in the chain has been laborious and taken a long time. That changed when a computer programmer named David Jacobs received a kidney transplant. He had been waiting on a deceased donor list, when a live donor came along -- someone nice enough to give away a kidney to a stranger. Jacobs paid it forward with his programming skills, creating MatchGrid, a program that genetically matches up donor pairs or chains quickly. \"When we did a five-way swap a few years ago, which was one of the largest, it took about three to four months. We did this in about three weeks,\" Jacobs said. But this chain wouldn\\'t have worked so quickly without Broussard\\'s generosity -- or may not have worked at all. \"The significance of the altruistic donor is that it opens up possibilities for pairing compatible donors and recipients,\" said Dr. Steven Katznelson. \"Where there had been only three or four options, with the inclusion of the altruistic donor, we had 140 options to consider for matching donors and recipients.\" And that\\'s divine, Broussard\\'s friend Shirley Williams wrote in a comment her on Broussard\\'s Facebook page. \"You are a true angel my friend.\"',\n",
       "   '(CNN)On the 6th of April 1996, San Jose Clash and DC United strode out in front of 31,683 expectant fans at the Spartan Stadium in San Jose, California. The historic occasion was the first ever Major League Soccer match -- a brave new dawn for the world\\'s favorite sport in a land its charms had yet to conquer. Summarizing the action for ESPN, commentator Ty Keough eagerly described the momentous \"birth of a new era for American soccer.\" Looking back at footage from that balmy evening now it\\'s hard not to feel a certain nostalgia. Baggy shirts, questionable hairstyles and strange rule adaptations to make games more exciting were all part of the formative MLS experience. Countdown clocks were employed to provide drama at the end of each half. Even more bizarrely, tied games were settled by shootouts that saw attacking players run with the ball from 35-yards out before attempting to beat the opposing goalkeeper. As the MLS prepares to mark the beginning of its 20th season, it\\'s hard to comprehend just how much the league has progressed in the intervening period. Long gone is the desire to tamper with the rules of the game for a start. Attendances are higher than ever before while the number of teams involved has doubled from 10 in the 1996 campaign to 20 in 2015. A further four are set to be added by 2020. On top of this, the new season is the first of a new domestic TV and media rights deal with FOX, ESPN and Univision worth $700 million over eight years. This figure may pale beside the $5.1 billion recently paid by UK broadcasters for the English Premier League, the richest football league in the world, but it represents a tripling in value of the previous MLS deal. According to Phil Rawlins, co-primary owner and president of the new MLS franchise, Orlando City Soccer Club, \"the industry and the game itself has moved on dramatically\" in the U.S.. He believes what would equal 50 years growth in most other industries has been experienced in the first two decades of the MLS. Rawlins\\' club is a prime example of this rapid transformation. He describes players being pushed out of changing facilities because of a schedule clash with a yoga class not so long ago. This weekend 60,000 fans are expected to witness Orlando City\\'s opening weekend fixture against New York City, another new club making their MLS bow. World Cup winners Kaka and David Villa will turn out for Orlando and New York City respectively. \"We\\'re just on the crest of the wave at the moment,\" Rawlins said of football\\'s American progress. \"Can it be the number two, number three sport in this country? Yes, I think it can. And it can be in a short space of time.\" These positive assertions are backed by the huge interest U.S. fans showed in last year\\'s World Cup in Brazil. Team USA\\'s group stage clash with Portugal attracted 25 million viewers, according to figures from TV ratings firm, Nielsen. That\\'s considerably more than the 15 million baseball\\'s 2013 World Series averaged on FOX or the similar audience that tuned into the 2014 NBA finals on ABC. Anyone who saw 20,000 pumped-up young fans pack out Chicago\\'s Grant Park to cheer on their country via big screens, meanwhile, would find it hard to argue against soccer in the U.S. now being anything other than a big deal. Reaching this promising stage, however, has been anything but a smooth ride. The MLS was reported to have lost as much as $250 million in its first five years while average attendances initially dwindled after the inaugural season. Three teams -- Miami Fusion, Tampa Bay Mutiny (both in 2001) and Chivas USA (2014) -- were disbanded along the way due to a mixture of lack of fan interest and ownership troubles. A report by Forbes at the end of 2013, meanwhile, claimed that only 10 out of 19 MLS teams were profitable. And as recently as this week, MLS players looked like they could be going on strike over wages and the right of players to become free agents when their contracts end. Then there\\'s the way the league develops, attracts and trades players. A salary cap restricts the amount teams can spend on playing squads. Each side, however, has a number of spaces that can be allocated to \"off budget\" signings which are not included within the cap. This includes promising Generation Adidas players who enter the MLS through the draft systems before completing their college education. Homegrown players from club\\'s development academies are also exempt as are a maximum of three designated players (DPs), usually stellar international names whose wages and transfer fees will be covered by club owners or sponsors. One of the main criticisms of the MLS and its complex player acquisition rulebook is that while it does entice prominent stars of the game like David Beckham, Freddie Ljungberg and Thierry Henry to appear in the MLS, it only does so when their careers are on a downward trajectory. Why would an exceptional player want to move to a league that can only attract a handful of top talents at any one time, after all? And herein lies one of the leagues biggest challenges in attracting and keeping the talented players fans want to see. Although the likes of the salary cap encourages fiscal probity, it means MLS teams are restricted by rules clubs in other markets are not. Head coach of Sporting Kansas, Peter Vermes, highlighted these difficulties in comments carried by the Kansas City Star newspaper last year. \"We\\'re in a place where at times you can\\'t compete with foreign clubs because of the kind of dynamics they have in regards to finances. We have a salary cap. They don\\'t,\" Vermes said. According to Paulo Teixeira, a football agent who has worked to bring in and sell players from the league in recent years, current philosophies with regards player-trading may be have to be tweaked to help the MLS grow yet further. He describes the importance of placing an emphasis on attracting younger players with European passports. Such talented individuals will have a sell-on value that can be recouped by the league and their clubs if they move on from the MLS to the biggest and wealthiest leagues across the Atlantic. Theoretically, at least, this money can then be reinvested in the league, player development and attracting yet more promising players to the MLS. This in turn will raise the standard further. An early example of this strategy can perhaps be found in the transfer of Oriol Rossell, a Spanish midfielder who moved from Sporting Kansas to Sporting Lisbon last year in a deal brokered by Teixeira. Rossell arrived on a free transfer aged 20 after being released by FC Barcelona in 2012. He excelled at Kansas, winning the MLS Cup before being sold to the Portuguese giants at a profit in June 2014. Teixeira is quick to make clear such plans would need good scouting systems to truly flourish. It could also be achieved by signing DPs closer to the peak stage of their career, he added. This last point is something that appears be happening already. \"Before they used to have a lot of big names who could no longer run in Europe,\" Teixeira said. \"(But) Villa is not an old guy, (Frank) Lampard is still going strong\" and both could still offer something to teams in Europe, he said by way of example of New York City\\'s first DP signings. Nevertheless, he continued, the signing of more young players with big potential \"is probably something we\\'ll see more of.\" Whether Teixeira is correct will become apparent in the months and years ahead. Either way, that brave new MLS dawn that broke over San Jose back in 1996 has turned into a bright morning. CNN\\'s Don Riddell contributed to this story.'],\n",
       "  'highlights': ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .',\n",
       "   'The 20th MLS season begins this weekend . League has changed dramatically since its inception in 1996 . Some question whether rules regarding salary caps and transfers need to change .'],\n",
       "  'id': ['a4942dd663020ca54575471657a0af38d82897d6',\n",
       "   '4157bc4da185971e2742f349d69a037343bc0d95']},\n",
       " {'article': ['(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC\\'s founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\" Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis. As members of the court, Palestinians may be subject to counter-charges as well. Israel and the United States, neither of which is an ICC member, opposed the Palestinians\\' efforts to join the body. But Palestinian Foreign Minister Riad al-Malki, speaking at Wednesday\\'s ceremony, said it was a move toward greater justice. \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. \"Indeed, today brings us closer to our shared goals of justice and peace.\" Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute. These are substantive commitments, which cannot be taken lightly,\" she said. Rights group Human Rights Watch welcomed the development. \"Governments seeking to penalize Palestine for joining the ICC should immediately end their pressure, and countries that support universal acceptance of the court\\'s treaty should speak out to welcome its membership,\" said Balkees Jarrah, international justice counsel for the group. \"What\\'s objectionable is the attempts to undermine international justice, not Palestine\\'s decision to join a treaty to which over 100 countries around the world are members.\" In January, when the preliminary ICC examination was opened, Israeli Prime Minister Benjamin Netanyahu described it as an outrage, saying the court was overstepping its boundaries. The United States also said it \"strongly\" disagreed with the court\\'s decision. \"As we have said repeatedly, we do not believe that Palestine is a state and therefore we do not believe that it is eligible to join the ICC,\" the State Department said in a statement. It urged the warring sides to resolve their differences through direct negotiations. \"We will continue to oppose actions against Israel at the ICC as counterproductive to the cause of peace,\" it said. But the ICC begs to differ with the definition of a state for its purposes and refers to the territories as \"Palestine.\" While a preliminary examination is not a formal investigation, it allows the court to review evidence and determine whether to investigate suspects on both sides. Prosecutor Fatou Bensouda said her office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecute genocide, crimes against humanity and war crimes. CNN\\'s Vasco Cotovio, Kareem Khadder and Faith Karimi contributed to this report.',\n",
       "   '(CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided mercy killing and then buried in a field -- only to survive. That\\'s according to Washington State University, where the dog -- a friendly white-and-black bully breed mix now named Theia -- has been receiving care at the Veterinary Teaching Hospital. Four days after her apparent death, the dog managed to stagger to a nearby farm, dirt-covered and emaciated, where she was found by a worker who took her to a vet for help. She was taken in by Moses Lake, Washington, resident Sara Mellado. \"Considering everything that she\\'s been through, she\\'s incredibly gentle and loving,\" Mellado said, according to WSU News. \"She\\'s a true miracle dog and she deserves a good life.\" Theia is only one year old but the dog\\'s brush with death did not leave her unscathed. She suffered a dislocated jaw, leg injuries and a caved-in sinus cavity -- and still requires surgery to help her breathe. The veterinary hospital\\'s Good Samaritan Fund committee awarded some money to help pay for the dog\\'s treatment, but Mellado has set up a fundraising page to help meet the remaining cost of the dog\\'s care. She\\'s also created a Facebook page to keep supporters updated. Donors have already surpassed the $10,000 target, inspired by Theia\\'s tale of survival against the odds. On the fundraising page, Mellado writes, \"She is in desperate need of extensive medical procedures to fix her nasal damage and reset her jaw. I agreed to foster her until she finally found a loving home.\" She is dedicated to making sure Theia gets the medical attention she needs, Mellado adds, and wants to \"make sure she gets placed in a family where this will never happen to her again!\" Any additional funds raised will be \"paid forward\" to help other animals. Theia is not the only animal to apparently rise from the grave in recent weeks. A cat in Tampa, Florida, found seemingly dead after he was hit by a car in January, showed up alive in a neighbor\\'s yard five days after he was buried by his owner. The cat was in bad shape, with maggots covering open wounds on his body and a ruined left eye, but remarkably survived with the help of treatment from the Humane Society.'],\n",
       "  'highlights': ['Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June . Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .',\n",
       "   'Theia, a bully breed mix, was apparently hit by a car, whacked with a hammer and buried in a field . \"She\\'s a true miracle dog and she deserves a good life,\" says Sara Mellado, who is looking for a home for Theia .'],\n",
       "  'id': ['f001ec5c4704938247d27a44948eebb37ae98d01',\n",
       "   '230c522854991d053fe98a718b1defa077a8efef']})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T21:47:55.772476Z",
     "start_time": "2025-01-11T21:38:49.471766Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_data(examples):\n",
    "    inputs = [f\"summarize: {article}\" for article in examples['article']]\n",
    "    targets = examples['highlights']\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    model_inputs['labels'] = tokenizer(\n",
    "        targets,\n",
    "        max_length=150,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "    )['input_ids']\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "train_data_tokenized = train_data.map(\n",
    "    tokenize_data,\n",
    "    batched=True,\n",
    "    remove_columns=['article', 'highlights'],\n",
    "    batch_size=128,\n",
    ")\n",
    "\n",
    "val_data_tokenized = val_data.map(\n",
    "    tokenize_data,\n",
    "    batched=True,\n",
    "    remove_columns=['article', 'highlights'],\n",
    "    batch_size=128,\n",
    ")\n",
    "\n",
    "test_data_tokenized = test_data.map(\n",
    "    tokenize_data,\n",
    "    batched=True,\n",
    "    remove_columns=['article', 'highlights'],\n",
    "    batch_size=128,\n",
    ")\n",
    "\n",
    "train_data_tokenized = train_data_tokenized.with_format(\"torch\")\n",
    "val_data_tokenized = val_data_tokenized.with_format(\"torch\")\n",
    "test_data_tokenized = test_data_tokenized.with_format(\"torch\")\n",
    "\n",
    "print(train_data_tokenized[0])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 287113/287113 [08:23<00:00, 569.76 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13368/13368 [00:22<00:00, 585.37 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11490/11490 [00:19<00:00, 595.16 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '42c027e4ff9730fbb3de84c1af0d2c506e41c3e4', 'input_ids': tensor([21603,    10,   301, 24796,  4170,     6,  2789,    41, 18844,    61,\n",
      "         1636,  8929, 16023,  2213,  4173,  6324, 12591,    15, 11391,   592,\n",
      "           12,     3,     9,  2196,  3996,  1755,   770,  8785,   591, 11039,\n",
      "          770,    61, 13462,    38,     3,    88,  5050,   507,    30,  2089,\n",
      "            6,    68,     3,    88, 10419,     7,     8,   540,   751,    31,\n",
      "           17,  4061,     3,     9, 10783,    30,   376,     5,  4173,  6324,\n",
      "        12591,    15,    38,  8929, 16023,    16,    96, 15537,   651, 16023,\n",
      "           11,     8,  5197,    13,     8, 12308,   121,   304,     8, 19142,\n",
      "           13, 29517,  6710,   343,     7,   300,     8,   296,     6,     8,\n",
      "         1021,  7556,   845,     3,    88,    65,   150,  1390,    12,  9030,\n",
      "           17,   449,   112,  1723,   550,    30,  1006,  2948,     6,  3281,\n",
      "           11, 17086,  2251,     5,    96,   196,   278,    31,    17,   515,\n",
      "           12,    36,    80,    13,   273,   151,   113,     6,    38,  1116,\n",
      "           38,    79,   919, 14985,  8247,   805,  1452,     3,     9,  3805,\n",
      "         2100,   443,  1232,    42,   424,  1126,   976,     3,    88,  1219,\n",
      "           46,  3746,  2772,    49,  2283,    48,   847,     5,    96,   196,\n",
      "          278,    31,    17,   317,    27,    31,   195,    36,  1989, 28887,\n",
      "            5,    96,   634,   378,    27,   114,  2611,    33,   378,    24,\n",
      "          583,    81,   335,  7051,  1636,  1335,    11,  3190,     7,    11,\n",
      "         5677,     7,   535,   486, 14985,  6324, 12591,    15,    56,    36,\n",
      "            3,   179,    12, 24068,    16,     3,     9,  2653,     6,   805,\n",
      "            3,     9,  3281,    16,     3,     9, 11943,    42,   217,     8,\n",
      "        12082,   814,    96,  4489,     7,  1625,    10,  2733,  2466,   976,\n",
      "         1083,  1296,  1747,   666,   112,   381,    80,  1974,    30,     8,\n",
      "         1270,  1367,   828,  5059,     5,  9487,    13,   149,     3,    88,\n",
      "           31,   195,  3946,   112, 15754,  3591,    33,   365,  6215,     7,\n",
      "            5,   978,  3102,    11,   452,   343,   141,   150,  1670,    30,\n",
      "          112,  1390,     5,    96,   196,    31,   195,  1728,    43,   128,\n",
      "         1843,    13,  1088,   976,     3,    88,   243,    16,    46,  2772,\n",
      "            5,    96, 12599,  5839,    13,    25,    56,    36,  1183,    81,\n",
      "           34,   535,  6324, 12591,    15,    31,     7,  8783,    45,     8,\n",
      "          166,   874, 16023,  4852,    43,   118,  1213,    16,     3,     9,\n",
      "         2019,  3069,    84,     3,    88,    65,    59,   118,     3,   179,\n",
      "           12,  1586,     5,     3,  4868,   112,  1710, 10393,    11, 20816,\n",
      "            6,     8,  7556,   845,     3,    88,    19,  2627,   112,  1922,\n",
      "            3, 16804,    30,     8,  1591,     5,    96, 24337,    33,   373,\n",
      "          479,    12,   497,     3,    31,  2168,    26,  2213,  1550,   326,\n",
      "            8,  6579,     7,     6,    31,   121,     3,    88,  1219, 19644,\n",
      "          336,   847,     5,    96, 11836,    27,   653,   182,   614,    59,\n",
      "           12,   281,    24,   194,   250,    34,   133,    36,   396,   514,\n",
      "           21,   135,   535,   978,  1251,    91,    53,    38,     8,  4940,\n",
      "        25027,    16,    96, 15537,   651, 16023,    11,     8,  5197,    13,\n",
      "            8, 12308,   121,    19,  7814,  3187,    30,   321,  4458,    13,\n",
      "            8,  9640,    11,     3,    88,    56, 21504,     8,  1075,    16,\n",
      "            8,   336,   192,  4852,     5,  4195,    27,    18,  1649,  1493,\n",
      "           49,   428,   160,  1132,    13, 16023,    31,     7,  1251,  1168,\n",
      "            3,     5,   290,    19,   280,  1909, 16023,     6,   983,     5,\n",
      "           37,  1524,    49,    65,     3, 25403,     3,     9,  1424,  1974,\n",
      "          718,    96,  7008,  7508,  4496,   976,    81,  2291, 17806,  6636,\n",
      "         4320,   102,   697,    11,   112,   520,     6,   788,    21,  1576,\n",
      "          865,    48,   215,     5,   216,    56,    92,  2385,    16,    96,\n",
      "        29835,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor([ 8929, 16023,  2213,  4173,  6324, 12591,    15,  2347,  3996,  1755,\n",
      "          329, 13462,    38,     3,    88,  5050,   507,  2089,     3,     5,\n",
      "         5209,  7556,   845,     3,    88,    65,   150,  1390,    12,  9030,\n",
      "           17,   449,   112,  1723,   550,     3,     5,  6324, 12591,    15,\n",
      "           31,     7,  8783,    45,   166,   874, 16023,  4852,    43,   118,\n",
      "         1213,    16,  2019,  3069,     3,     5,     1,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T21:48:48.851219Z",
     "start_time": "2025-01-11T21:48:08.338528Z"
    }
   },
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=0.01,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    bf16=True, #fp16=True for non-Macs\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    save_steps=1000,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data_tokenized,\n",
    "    eval_dataset=val_data_tokenized,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='26916' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   24/26916 00:37 < 12:37:58, 0.59 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 34\u001B[0m\n\u001B[1;32m      5\u001B[0m training_args \u001B[38;5;241m=\u001B[39m Seq2SeqTrainingArguments(\n\u001B[1;32m      6\u001B[0m     output_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./results\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      7\u001B[0m     eval_strategy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     23\u001B[0m     save_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m,\n\u001B[1;32m     24\u001B[0m )\n\u001B[1;32m     26\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Seq2SeqTrainer(\n\u001B[1;32m     27\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     28\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     31\u001B[0m     processing_class\u001B[38;5;241m=\u001B[39mtokenizer,\n\u001B[1;32m     32\u001B[0m )\n\u001B[0;32m---> 34\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/transformers/trainer.py:2171\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   2169\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   2170\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2171\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_training_loop(\n\u001B[1;32m   2172\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[1;32m   2173\u001B[0m         resume_from_checkpoint\u001B[38;5;241m=\u001B[39mresume_from_checkpoint,\n\u001B[1;32m   2174\u001B[0m         trial\u001B[38;5;241m=\u001B[39mtrial,\n\u001B[1;32m   2175\u001B[0m         ignore_keys_for_eval\u001B[38;5;241m=\u001B[39mignore_keys_for_eval,\n\u001B[1;32m   2176\u001B[0m     )\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/transformers/trainer.py:2531\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2524\u001B[0m context \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   2525\u001B[0m     functools\u001B[38;5;241m.\u001B[39mpartial(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mno_sync, model\u001B[38;5;241m=\u001B[39mmodel)\n\u001B[1;32m   2526\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(batch_samples) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   2527\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mdistributed_type \u001B[38;5;241m!=\u001B[39m DistributedType\u001B[38;5;241m.\u001B[39mDEEPSPEED\n\u001B[1;32m   2528\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m contextlib\u001B[38;5;241m.\u001B[39mnullcontext\n\u001B[1;32m   2529\u001B[0m )\n\u001B[1;32m   2530\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[0;32m-> 2531\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(model, inputs, num_items_in_batch)\n\u001B[1;32m   2533\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   2534\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   2535\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[1;32m   2536\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   2537\u001B[0m ):\n\u001B[1;32m   2538\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   2539\u001B[0m     tr_loss \u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m+\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/transformers/trainer.py:3678\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs, num_items_in_batch)\u001B[0m\n\u001B[1;32m   3676\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss(model, inputs)\n\u001B[1;32m   3677\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 3678\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss(model, inputs, num_items_in_batch\u001B[38;5;241m=\u001B[39mnum_items_in_batch)\n\u001B[1;32m   3680\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m inputs\n\u001B[1;32m   3681\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   3682\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mtorch_empty_cache_steps \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   3683\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mtorch_empty_cache_steps \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m   3684\u001B[0m ):\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/transformers/trainer.py:3734\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001B[0m\n\u001B[1;32m   3732\u001B[0m         loss_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_items_in_batch\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m num_items_in_batch\n\u001B[1;32m   3733\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mloss_kwargs}\n\u001B[0;32m-> 3734\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)\n\u001B[1;32m   3735\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[1;32m   3736\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[1;32m   3737\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1891\u001B[0m, in \u001B[0;36mT5ForConditionalGeneration.forward\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[1;32m   1888\u001B[0m         decoder_attention_mask \u001B[38;5;241m=\u001B[39m decoder_attention_mask\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder\u001B[38;5;241m.\u001B[39mfirst_device)\n\u001B[1;32m   1890\u001B[0m \u001B[38;5;66;03m# Decode\u001B[39;00m\n\u001B[0;32m-> 1891\u001B[0m decoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(\n\u001B[1;32m   1892\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39mdecoder_input_ids,\n\u001B[1;32m   1893\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mdecoder_attention_mask,\n\u001B[1;32m   1894\u001B[0m     inputs_embeds\u001B[38;5;241m=\u001B[39mdecoder_inputs_embeds,\n\u001B[1;32m   1895\u001B[0m     past_key_values\u001B[38;5;241m=\u001B[39mpast_key_values,\n\u001B[1;32m   1896\u001B[0m     encoder_hidden_states\u001B[38;5;241m=\u001B[39mhidden_states,\n\u001B[1;32m   1897\u001B[0m     encoder_attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m   1898\u001B[0m     head_mask\u001B[38;5;241m=\u001B[39mdecoder_head_mask,\n\u001B[1;32m   1899\u001B[0m     cross_attn_head_mask\u001B[38;5;241m=\u001B[39mcross_attn_head_mask,\n\u001B[1;32m   1900\u001B[0m     use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[1;32m   1901\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m   1902\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[1;32m   1903\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m   1904\u001B[0m     cache_position\u001B[38;5;241m=\u001B[39mcache_position,\n\u001B[1;32m   1905\u001B[0m )\n\u001B[1;32m   1907\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m decoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1909\u001B[0m \u001B[38;5;66;03m# Set device for model parallelism\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1124\u001B[0m, in \u001B[0;36mT5Stack.forward\u001B[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[1;32m   1107\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m   1108\u001B[0m         layer_module\u001B[38;5;241m.\u001B[39mforward,\n\u001B[1;32m   1109\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1121\u001B[0m         cache_position,\n\u001B[1;32m   1122\u001B[0m     )\n\u001B[1;32m   1123\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1124\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m layer_module(\n\u001B[1;32m   1125\u001B[0m         hidden_states,\n\u001B[1;32m   1126\u001B[0m         attention_mask\u001B[38;5;241m=\u001B[39mcausal_mask,\n\u001B[1;32m   1127\u001B[0m         position_bias\u001B[38;5;241m=\u001B[39mposition_bias,\n\u001B[1;32m   1128\u001B[0m         encoder_hidden_states\u001B[38;5;241m=\u001B[39mencoder_hidden_states,\n\u001B[1;32m   1129\u001B[0m         encoder_attention_mask\u001B[38;5;241m=\u001B[39mencoder_extended_attention_mask,\n\u001B[1;32m   1130\u001B[0m         encoder_decoder_position_bias\u001B[38;5;241m=\u001B[39mencoder_decoder_position_bias,\n\u001B[1;32m   1131\u001B[0m         layer_head_mask\u001B[38;5;241m=\u001B[39mlayer_head_mask,\n\u001B[1;32m   1132\u001B[0m         cross_attn_layer_head_mask\u001B[38;5;241m=\u001B[39mcross_attn_layer_head_mask,\n\u001B[1;32m   1133\u001B[0m         past_key_value\u001B[38;5;241m=\u001B[39mpast_key_values,\n\u001B[1;32m   1134\u001B[0m         use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[1;32m   1135\u001B[0m         output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m   1136\u001B[0m         return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m   1137\u001B[0m         cache_position\u001B[38;5;241m=\u001B[39mcache_position,\n\u001B[1;32m   1138\u001B[0m     )\n\u001B[1;32m   1140\u001B[0m \u001B[38;5;66;03m# layer_outputs is a tuple with:\u001B[39;00m\n\u001B[1;32m   1141\u001B[0m \u001B[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001B[39;00m\n\u001B[1;32m   1142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:699\u001B[0m, in \u001B[0;36mT5Block.forward\u001B[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001B[0m\n\u001B[1;32m    697\u001B[0m do_cross_attention \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_decoder \u001B[38;5;129;01mand\u001B[39;00m encoder_hidden_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m do_cross_attention:\n\u001B[0;32m--> 699\u001B[0m     cross_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer[\u001B[38;5;241m1\u001B[39m](\n\u001B[1;32m    700\u001B[0m         hidden_states,\n\u001B[1;32m    701\u001B[0m         key_value_states\u001B[38;5;241m=\u001B[39mencoder_hidden_states,\n\u001B[1;32m    702\u001B[0m         attention_mask\u001B[38;5;241m=\u001B[39mencoder_attention_mask,\n\u001B[1;32m    703\u001B[0m         position_bias\u001B[38;5;241m=\u001B[39mencoder_decoder_position_bias,\n\u001B[1;32m    704\u001B[0m         layer_head_mask\u001B[38;5;241m=\u001B[39mcross_attn_layer_head_mask,\n\u001B[1;32m    705\u001B[0m         past_key_value\u001B[38;5;241m=\u001B[39mpast_key_value,\n\u001B[1;32m    706\u001B[0m         query_length\u001B[38;5;241m=\u001B[39mcache_position[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m    707\u001B[0m         use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[1;32m    708\u001B[0m         output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m    709\u001B[0m     )\n\u001B[1;32m    710\u001B[0m     hidden_states, past_key_value \u001B[38;5;241m=\u001B[39m cross_attention_outputs[:\u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m    712\u001B[0m     \u001B[38;5;66;03m# clamp inf values to enable fp16 training\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:629\u001B[0m, in \u001B[0;36mT5LayerCrossAttention.forward\u001B[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions, cache_position)\u001B[0m\n\u001B[1;32m    615\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    616\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    617\u001B[0m     hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    626\u001B[0m     cache_position\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    627\u001B[0m ):\n\u001B[1;32m    628\u001B[0m     normed_hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_norm(hidden_states)\n\u001B[0;32m--> 629\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mEncDecAttention(\n\u001B[1;32m    630\u001B[0m         normed_hidden_states,\n\u001B[1;32m    631\u001B[0m         mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m    632\u001B[0m         key_value_states\u001B[38;5;241m=\u001B[39mkey_value_states,\n\u001B[1;32m    633\u001B[0m         position_bias\u001B[38;5;241m=\u001B[39mposition_bias,\n\u001B[1;32m    634\u001B[0m         layer_head_mask\u001B[38;5;241m=\u001B[39mlayer_head_mask,\n\u001B[1;32m    635\u001B[0m         past_key_value\u001B[38;5;241m=\u001B[39mpast_key_value,\n\u001B[1;32m    636\u001B[0m         use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[1;32m    637\u001B[0m         query_length\u001B[38;5;241m=\u001B[39mquery_length,\n\u001B[1;32m    638\u001B[0m         output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m    639\u001B[0m         cache_position\u001B[38;5;241m=\u001B[39mcache_position,\n\u001B[1;32m    640\u001B[0m     )\n\u001B[1;32m    641\u001B[0m     layer_output \u001B[38;5;241m=\u001B[39m hidden_states \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(attention_output[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    642\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (layer_output,) \u001B[38;5;241m+\u001B[39m attention_output[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:553\u001B[0m, in \u001B[0;36mT5Attention.forward\u001B[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001B[0m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;66;03m# (batch_size, n_heads, seq_length, key_length)\u001B[39;00m\n\u001B[1;32m    552\u001B[0m attn_weights \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39msoftmax(scores\u001B[38;5;241m.\u001B[39mfloat(), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mtype_as(scores)\n\u001B[0;32m--> 553\u001B[0m attn_weights \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mdropout(attn_weights, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining)\n\u001B[1;32m    555\u001B[0m \u001B[38;5;66;03m# Mask heads if we want to\u001B[39;00m\n\u001B[1;32m    556\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m layer_head_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.12/site-packages/torch/nn/functional.py:1425\u001B[0m, in \u001B[0;36mdropout\u001B[0;34m(input, p, training, inplace)\u001B[0m\n\u001B[1;32m   1422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m p \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0.0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m p \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1.0\u001B[39m:\n\u001B[1;32m   1423\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdropout probability has to be between 0 and 1, but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mp\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1424\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m-> 1425\u001B[0m     _VF\u001B[38;5;241m.\u001B[39mdropout_(\u001B[38;5;28minput\u001B[39m, p, training) \u001B[38;5;28;01mif\u001B[39;00m inplace \u001B[38;5;28;01melse\u001B[39;00m _VF\u001B[38;5;241m.\u001B[39mdropout(\u001B[38;5;28minput\u001B[39m, p, training)\n\u001B[1;32m   1426\u001B[0m )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate(eval_dataset=val_data_tokenized)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.evaluate(eval_dataset=test_data_tokenized)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions for the test dataset\n",
    "test_sample = test_data_tokenized[0]\n",
    "input_ids = test_sample['input_ids']\n",
    "outputs = model.generate(input_ids=input_ids.unsqueeze(0), max_length=150)\n",
    "\n",
    "# Decode predictions\n",
    "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: './fine_tuned_model'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mHFValidationError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py:403\u001B[0m, in \u001B[0;36mcached_file\u001B[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[0;32m    401\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    402\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[1;32m--> 403\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    404\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    405\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    406\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    407\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    409\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    412\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    413\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    414\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    415\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    416\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    417\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m GatedRepoError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py:106\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m arg_name \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrepo_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto_id\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m--> 106\u001B[0m     \u001B[43mvalidate_repo_id\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m arg_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m arg_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py:160\u001B[0m, in \u001B[0;36mvalidate_repo_id\u001B[1;34m(repo_id)\u001B[0m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m REPO_ID_REGEX\u001B[38;5;241m.\u001B[39mmatch(repo_id):\n\u001B[1;32m--> 160\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HFValidationError(\n\u001B[0;32m    161\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRepo id must use alphanumeric chars or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m--\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m..\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m are\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    162\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m forbidden, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m cannot start or end the name, max length is 96:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    163\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrepo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    164\u001B[0m     )\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m repo_id \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m..\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m repo_id:\n",
      "\u001B[1;31mHFValidationError\u001B[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './fine_tuned_model'.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 11\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Wczytanie modelu i tokenizatora\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForSeq2SeqLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./fine_tuned_model\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./fine_tuned_model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# ZaÅ‚adowanie danych testowych\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\auto\\auto_factory.py:487\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m    484\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m commit_hash \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    485\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(config, PretrainedConfig):\n\u001B[0;32m    486\u001B[0m         \u001B[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001B[39;00m\n\u001B[1;32m--> 487\u001B[0m         resolved_config_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m            \u001B[49m\u001B[43mCONFIG_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_gated_repo\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_missing_entries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_connection_errors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    495\u001B[0m         commit_hash \u001B[38;5;241m=\u001B[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001B[0;32m    496\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py:469\u001B[0m, in \u001B[0;36mcached_file\u001B[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[0;32m    467\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThere was a specific connection error when trying to load \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00merr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    468\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m HFValidationError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 469\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[0;32m    470\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncorrect path_or_model_id: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    471\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    472\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resolved_file\n",
      "\u001B[1;31mOSError\u001B[0m: Incorrect path_or_model_id: './fine_tuned_model'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from rouge_score import rouge_scorer\n",
    "import torch\n",
    "\n",
    "# Wczytanie modelu i tokenizatora\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./fine_tuned_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_model\")\n",
    "\n",
    "# ZaÅ‚adowanie danych testowych\n",
    "ds = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\")\n",
    "df_test = ds['test'].to_pandas()\n",
    "\n",
    "# Funkcja do streszczania tekstÃ³w\n",
    "def summarize(text):\n",
    "    inputs = tokenizer(f\"summarize: {text}\", return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    outputs = model.generate(input_ids=inputs['input_ids'], max_length=150)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Funkcja do ewaluacji modelu na danych testowych\n",
    "def evaluate_model():\n",
    "    predictions = []\n",
    "    references = df_test[\"highlights\"].tolist()\n",
    "    \n",
    "    for article in df_test[\"article\"]:\n",
    "        summary = summarize(article)\n",
    "        predictions.append(summary)\n",
    "    \n",
    "    return predictions, references\n",
    "\n",
    "# Obliczanie metryk ROUGE\n",
    "def compute_rouge(predictions, references):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "    rouge1_scores = []\n",
    "    rouge2_scores = []\n",
    "    rougeL_scores = []\n",
    "\n",
    "    for ref, pred in zip(references, predictions):\n",
    "        scores = scorer.score(ref, pred)\n",
    "        rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "        rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "        rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "\n",
    "    return rouge1_scores, rouge2_scores, rougeL_scores\n",
    "\n",
    "# b. Tworzenie interaktywnej tablicy w Plotly Dash\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Layout tablicy\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Summarization Model Dashboard\"),\n",
    "\n",
    "    # WybÃ³r trybu testowania\n",
    "    dcc.RadioItems(\n",
    "        id=\"test_mode\",\n",
    "        options=[\n",
    "            {'label': 'Test Dataset Sample', 'value': 'sample'},\n",
    "            {'label': 'Custom Input', 'value': 'custom'}\n",
    "        ],\n",
    "        value='sample',\n",
    "        labelStyle={'display': 'block'}\n",
    "    ),\n",
    "\n",
    "    # Pole do wprowadzania tekstu (dla trybu \"Custom Input\")\n",
    "    dcc.Textarea(\n",
    "        id=\"input_text\",\n",
    "        style={'width': '100%', 'height': 100},\n",
    "        placeholder=\"Enter text for summarization\"\n",
    "    ),\n",
    "\n",
    "    # Suwak do wyboru prÃ³bki z danych testowych\n",
    "    dcc.Slider(\n",
    "        id='sample_id',\n",
    "        min=0,\n",
    "        max=len(df_test)-1,\n",
    "        step=1,\n",
    "        value=0,\n",
    "        marks={i: f'Sample {i}' for i in range(0, len(df_test), 100)}\n",
    "    ),\n",
    "\n",
    "    html.Button('Generate Summary', id='generate_button', n_clicks=0),\n",
    "    html.H3(\"Generated Summary\"),\n",
    "    html.Div(id='output_summary'),\n",
    "\n",
    "    # Wizualizacja wynikÃ³w - metryki ewaluacji\n",
    "    html.H3(\"Evaluation Metrics\"),\n",
    "    html.Button('Compute Evaluation', id='compute_metrics_button', n_clicks=0),\n",
    "    html.Div(id='rouge_scores'),\n",
    "\n",
    "    # Analiza bÅ‚Ä™dÃ³w\n",
    "    html.H3(\"Error Analysis\"),\n",
    "    html.Div(id='error_analysis')\n",
    "])\n",
    "\n",
    "# Callback do generowania streszczeÅ„\n",
    "@app.callback(\n",
    "    Output('output_summary', 'children'),\n",
    "    Input('generate_button', 'n_clicks'),\n",
    "    [Input('test_mode', 'value'), Input('input_text', 'value'), Input('sample_id', 'value')]\n",
    ")\n",
    "def generate_summary(n_clicks, test_mode, input_text, sample_id):\n",
    "    if test_mode == 'sample':\n",
    "        input_text = df_test.iloc[sample_id][\"article\"]\n",
    "    if input_text:\n",
    "        summary = summarize(input_text)\n",
    "        return summary\n",
    "    return \"No input provided.\"\n",
    "\n",
    "# Callback do obliczania metryk ROUGE\n",
    "@app.callback(\n",
    "    Output('rouge_scores', 'children'),\n",
    "    Input('compute_metrics_button', 'n_clicks')\n",
    ")\n",
    "def compute_metrics(n_clicks):\n",
    "    if n_clicks > 0:\n",
    "        predictions, references = evaluate_model()\n",
    "        rouge1_scores, rouge2_scores, rougeL_scores = compute_rouge(predictions, references)\n",
    "        rouge1_avg = sum(rouge1_scores) / len(rouge1_scores)\n",
    "        rouge2_avg = sum(rouge2_scores) / len(rouge2_scores)\n",
    "        rougeL_avg = sum(rougeL_scores) / len(rougeL_scores)\n",
    "        return f\"ROUGE-1: {rouge1_avg:.4f}, ROUGE-2: {rouge2_avg:.4f}, ROUGE-L: {rougeL_avg:.4f}\"\n",
    "    return \"Click to compute evaluation.\"\n",
    "\n",
    "# Callback do analizy bÅ‚Ä™dÃ³w (pierwsze 5 przykÅ‚adÃ³w)\n",
    "@app.callback(\n",
    "    Output('error_analysis', 'children'),\n",
    "    Input('compute_metrics_button', 'n_clicks')\n",
    ")\n",
    "def error_analysis(n_clicks):\n",
    "    if n_clicks > 0:\n",
    "        mismatches = []\n",
    "        for i, article in enumerate(df_test[\"article\"]):\n",
    "            generated_summary = summarize(article)\n",
    "            actual_summary = df_test.iloc[i][\"highlights\"]\n",
    "            if generated_summary != actual_summary:\n",
    "                mismatches.append((article, generated_summary, actual_summary))\n",
    "        return [\n",
    "            html.Div([\n",
    "                html.H4(f\"Mismatch {i+1}\"),\n",
    "                html.P(f\"Original Article: {mismatch[0][:300]}...\"),\n",
    "                html.P(f\"Generated Summary: {mismatch[1]}\"),\n",
    "                html.P(f\"Actual Summary: {mismatch[2]}\")\n",
    "            ]) for i, mismatch in enumerate(mismatches[:5])\n",
    "        ]\n",
    "    return \"Click to compute evaluation and view errors.\"\n",
    "\n",
    "# Uruchomienie aplikacji Dash w notebooku\n",
    "from jupyter_dash import JupyterDash\n",
    "app = JupyterDash(__name__)\n",
    "app.run_server(mode='inline')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
